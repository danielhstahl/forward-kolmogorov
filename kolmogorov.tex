\documentclass{article}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{cite}
\usepackage{float}
\usepackage{scrextend}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}

\setlength{\parindent}{0pt}
\newtheorem{theorem}{Theorem}
\theoremstyle{definition}
\newtheorem{definition}{Definition}

\begin{document}
\section{Backward and Forward Kolmogorov Equation}

This paper is focused on deriving both the Backward and Forward Kolmogorov equations.  These equations answer questions around how the density of a continuous stochastic differential equation evolves in both space and time.  This paper assumes an understanding of the theory of Brownian Motion and stochastic calculus (eg, existence and solutions to stochastic differential equations). For this paper, the stochastic differential equation under consideration is one in which a transition density exists and in which the dynamics are:

\begin{equation} \label{sde}
dX_t=\alpha(X_t, t) dt+\sigma(X_t, t) dW_t
\end{equation}

Where \(\alpha\) and \(\sigma\) satisfy the ``usual'' conditions and \(dW_t\) is an increment of Brownian Motion.

\section{Evolution of Expectation of Stochastic Different Equations}

\begin{definition}
	The \emph{generator} of a diffusion \(Z_t\) is defined as 
	\[\lim_{T \to 0} \frac{\mathbb{E}[f(Z_T)]-f(z)}{T} \]
\end{definition}

\begin{theorem}
Let \(X_t\) be the solution to \ref{sde}.  Then the generator \(A\) of \(X_t\) is the operator \(\alpha(x, t) \frac{\partial}{\partial x} +\frac{1}{2} \sigma^2(x, t) \frac{\partial ^2}{\partial x^2} \).  For the remainder of this paper the generator will be denoted \(A\).  

\end{theorem}

\begin{proof}
	By Ito's Lemma,
	\[\lim_{T \to 0} \frac{\mathbb{E}[f(X_T)]-f(x)}{T}\]
	\[=\lim_{T \to 0} \frac{f(x)+\mathbb{E}\left[ \int_0 ^ T \left( \alpha(X_s, s) \frac{\partial f}{\partial x} +\frac{1}{2} \sigma^2(X_s, s) \frac{\partial^2 f}{\partial x^2} \right) ds + \int_0^T \sigma(X_s, s)dW_s \right]-f(x)}{T} \]
	
	\[ = \lim_{T \to 0} \frac{ \int_0 ^ T \left( \mathbb{E}\left[\alpha(X_s, s) \frac{\partial f}{\partial x} +\frac{1}{2} \sigma^2(X_s, s) \frac{\partial^2 f}{\partial x^2} \right] \right) ds  }{T} \]
	
	\[ = \mathbb{E}\left[\alpha(x, t) \frac{\partial f}{\partial x} +\frac{1}{2} \sigma^2(x, t) \frac{\partial^2 f}{\partial x^2} \right] \]
	\[ = \alpha(x, t) \frac{\partial f}{\partial x} +\frac{1}{2} \sigma^2(x, t) \frac{\partial^2 f}{\partial x^2}\]
	
\end{proof}

\begin{theorem}\label{fk}
	Let \(X_t\) be the solution to \ref{sde} and define \(\tau=T-s\).  Then for any Borel measurable function \(h\),
	\(u(\tau, x)=\mathbb{E}[h(X_T)|\mathcal{F}_s]\) satisfies the partial differential equation
	\(\frac{\partial u}{\partial \tau} = Au \) with terminal condition \(u(0, x)=h(x)\)
	where \(A\) is the generator of \(X_t\),  and \(\mathcal{F}_t\) is the filtration generated by \(dW_t\).
	
\end{theorem}

\begin{proof}
	
	By definition, 
	
	\[Au=\lim_{r \to 0} \frac{\mathbb{E}\left[ u(\tau, X_{s+r}) \right] - u(\tau, x)}{r} \]
	
	\[ =  \lim_{r \to 0} \frac{\mathbb{E}\left[ \mathbb{E}\left[ h(X_{T+r}) | \mathcal{F}_{s+r} \right] \right] - u(\tau, x)}{r} \]
	
	\[ =  \lim_{r \to 0} \frac{ \mathbb{E}\left[ h(X_{T+r}) | \mathcal{F}_{s} \right] - u(\tau, x)}{r} \]
	
	\[ =  \lim_{r \to 0} \frac{ u(\tau+r, x) - u(\tau, x)}{r} \]
	
	\[= \frac{\partial u}{\partial \tau}\]
	

\end{proof}


\section{Backward Kolmogorov Equation}

The backward Kolmogorov equation is an application of \ref{fk}.  It describes, for a fixed point at time \(T\), how the conditional density of \(X_t\) evolves.  I write this conditional density as \(p(s, T, x, y)\) where \(s\) is the ``current'' time, \(x\) is the ``current'' value of \(X_t\), \(T\) is the ``terminal'' time, and \(y\) is the ``dummy'' variable for integration.  The expectation \(\mathbb{E}[g(X_T)|\mathcal{F}_s]\) can thus be written as \(\int_\mathbb{R} g(y) p(s, T, x, y) dy \).  In the special case that \(X_t\) is time homogeneous, this can be written as \(\int_\mathbb{R} g(z) p(\tau, z) dz \) where \(z=y-x\) and \(\tau=T-s\).  
\\
\\
\begin{theorem}\label{bk}
	Let \(X_t\) be defined as in \ref{sde}. If it exists, and fixing \(T\) and \(y\), the transition density \(p(s, T, x, y)\) of \(X_t\) is a solution to the following partial differential equation:
	\[\frac{\partial p}{\partial s} + Ap=0 \]
	With terminal condition \(p(T, T, x, y)=\delta(x-y)\)
\end{theorem}

\begin{proof}
	Let \(u_\delta (\tau, x)= \mathbb{E}\left[\delta(X_T-y)  | \mathcal{F}_s\right]\).
	By basic properties of delta functions, 
	\[u_\delta(\tau, x)=\mathbb{E}\left[\delta(X_T-y) | \mathcal{F}_s \right]=\int_\mathbb{R} \delta(\hat{y}-y) p(s, T, x, \hat{y}) d\hat{y}=p(s, T, x, y)\]
	From \ref{fk}, \(\frac{\partial u_\delta}{\partial \tau}=Au_\delta\).  Since \(\tau=T-s\), \(\frac{\partial u_\delta}{\partial s} = \frac{\partial u_\delta}{\partial \tau} \frac{\partial \tau}{\partial s}=-\frac{\partial u_\delta}{\partial \tau} \).  Putting it all together, 
	
	\[\frac{\partial p}{\partial s} + Ap=0 \]
	
\end{proof}

\section{Forward Kolmogorov Equation}

The forward Kolmogorov equation describes, for a fixed point of time \(s\) and \(x)\), how the conditional density of \(X_t\) evolves.  In many applications this is a more useful formulation.  For many applications we know \(s\) and \(x\), and are attempting to understand the potential outcomes in the future.  

\begin{theorem}\label{fk}
	Let \(X_t\) be defined as in \ref{sde}.  If it exists, and fixing \(s\) and \(x\), the transition density \(p(s, T, x, y)\) of \(X_t\) is a solution to the following partial differential equation:
	\[\frac{\partial p}{\partial T} + A^*p=0 \]
	With initial condition \(p(s, s, x, y)=\delta(x-y)\), where \(A^*f\) is defined as: \[-\frac{\partial \left(\alpha(y, t) f\right)}{\partial y} + \frac{1}{2}\frac{\partial^2 \left(\sigma(y, t) f\right) } {\partial y^2}   \]
\end{theorem}
\begin{proof}
	The adjoint of \(A\) is defined as an operator \(\hat{A}\) such that 
	\[\int_\mathbb{R} f(z) A g(z) dz = \int_\mathbb{R} g(z) \hat{A} f(z)\,\,\forall f, g \in \mathcal{D}   \]
	For our purposes, \(\mathcal{D}\) is the set of density functions.  Since densities integrate to one, these functions satisfy \(\lim_{z \to \infty } D(z) =0 \) and \(\lim_{z \to -\infty} D(z)=0\,\,\forall D \in \mathcal{D}\).
	\\
	\\
	To derive \(\hat{A}\),  
	\[\int_\mathbb{R} f(z) A g(z) dz  = \int_\mathbb{R}  f(z)  \alpha(z, t) \frac{\partial g}{\partial z} dz+\frac{1}{2} \int_\mathbb{R} f(z)\sigma^2(z, t) \frac{\partial^2 g}{\partial z^2} dz \]
	
	\[= - \int_\mathbb{R}  \frac{\partial \left( f(z)  \alpha(z, t) \right)}{\partial z} g(z) dz -\frac{1}{2} \int_\mathbb{R} \frac{\partial \left(f(z)\sigma^2(z, t)\right) }{\partial z} \frac{\partial g}{\partial z} dz   \]
	
	\[ = - \int_\mathbb{R}  \frac{\partial \left( f(z)  \alpha(z, t) \right)}{\partial z} g(z) dz +\frac{1}{2} \int_\mathbb{R} \frac{\partial ^2 \left(f(z)\sigma^2(z, t) \right)}{\partial z^2} g(z) dz   \]
	
	
	\[ \implies \hat{A}= -\frac{\partial \left(\alpha(y, t) f\right)}{\partial y} + \frac{1}{2}\frac{\partial^2 \left(\sigma(y, t) f\right) } {\partial y^2} =A^* \]
	
	Armed with the adjoint, I now proceed to directly compute the dynamics of the density.  
	\\
	\\
	By Dynkan's formula,
	
	\[ \mathbb{E}[h(X_T)|\mathcal{F}_s]= h(x)+\mathbb{E}\left[\int_s^T A h ds \right]  \]
	Substituting for the density, 
	\[\int_\mathbb{R} h(y) p(s, T, x, y) dy = h(x)+ \int_s^T  \int_\mathbb{R}p(s, v, x, y) A h(y)   dy dv   \]
	
	Taking the derivative with respect to \(T\) of both sides,
	\[\int_\mathbb{R} h(y) \frac{\partial p(s, T, x, y)}{\partial T} dy = \int_\mathbb{R}  p(s, T, x, y) A h(y) dy   \]
	
	Using the adjoint,
	\[\int_\mathbb{R} h(y) \frac{\partial p(s, T, x, y)}{\partial T} dy= \int_\mathbb{R}  h(y) A^* p(s, T, x, y) dy  \]
	Where the adjoint operates on the \(y\) variable.  The only way this equation holds for all \(h(y)\) is if 
	
	\[\frac{\partial p(s, T, x, y)}{\partial T} = A^* p(s, T, x, y)  \]
	
	
\end{proof}

\section{Examples}

\subsection{Brownian Motion}

When \(dX_t=dW_t\), the Backward equation becomes

\[\frac{\partial p} {\partial s} + \frac{1}{2} \frac{\partial^2 p}{\partial x^2} =0\]

The conditional density of a Brownian Motion is

\[p_{bm}(s, T, x, y)=\frac{1}{\sqrt{2\pi} \sqrt{T-s}} e^{-\frac{(y-x)^2}{2(T-s)}} \]

Taking the first derivative with respect to \(s\):

\[\frac{\partial p_{bm}(s, T, x, y)}{\partial s}=  \frac{1}{2}p_{bm}(s, T, x, y)\left(\frac{1}{T-s}-\frac{(y-x)^2}{(T-s)^2}\right)  \]

Taking the second derivative with respect to \(x\):

\[\frac{\partial^2 p_{bm}(s, T, x, y)}{\partial x^2}=  p_{bm}(s, T, x, y)\left(\frac{(y-x)^2}{(T-s)^2}-\frac{1}{T-s}\right)  \]

Combining,
\[\frac{\partial p} {\partial s} + \frac{1}{2} \frac{\partial^2 p}{\partial x^2} =0\]

The Forward equation becomes

\[\frac{\partial p} {\partial T} -\frac{1}{2} \frac{\partial^2 p}{\partial y^2} =0\]

Taking the first derivative with respect to \(T\):

\[\frac{\partial p_{bm}(s, T, x, y)}{\partial T}=  \frac{1}{2}p_{bm}(s, T, x, y)\left(\frac{(y-x)^2}{(T-s)^2}-\frac{1}{T-s}\right)  \]

Taking the second derivative with respect to \(y\):

\[\frac{\partial^2 p_{bm}(s, T, x, y)}{\partial y^2}=  p_{bm}(s, T, x, y)\left(\frac{(y-x)^2}{(T-s)^2}-\frac{1}{T-s}\right)  \]

Combining, 

\[\frac{\partial p} {\partial T} -\frac{1}{2} \frac{\partial^2 p}{\partial y^2} =0\]

\subsection{Geometric Brownian Motion}

When \(dX_t=\alpha X_t dt+\sigma X_t dW_t\), the Backward equation becomes

\[\frac{\partial p} {\partial s} +\alpha x \frac{\partial p}{\partial x} + \frac{1}{2} \sigma^2 x^2 \frac{\partial^2 p}{\partial x^2} =0\]

The conditional density of a Geometric Brownian Motion is

\[p_{gbm}(s, T, x, y)=\frac{1}{\sigma y\sqrt{2\pi} \sqrt{T-s} } e^{-\frac{\left( \log\left(\frac{y}{x}\right) -\left(\alpha-\frac{\sigma^2}{2}\right)(T-s)\right)^2}{2\sigma^2(T-s)}} \]

Taking the first derivative with respect to \(s\):


\begin{multline*}
\frac{\partial p_{gbm}(s, T, x, y)}{\partial s}  =  p_{gbm}(s, T, x, y) \frac{1}{2(T-s)} + \\p_{gbm}(s, T, x, y)\frac{ \log\left(\frac{y}{x}\right) -\left(\alpha-\frac{\sigma^2}{2}\right)(T-s)}{2(T-s)}   - \\p_{gbm}(s, T, x, y)\frac{ \log\left(\frac{y}{x}\right) -\left(\alpha-\frac{\sigma^2}{2}\right)(T-s)}{\sigma^2(T-s)}\alpha  -\\p_{gbm}(s, T, x, y)\frac{\left( \log\left(\frac{y}{x}\right) -\left(\alpha-\frac{\sigma^2}{2}\right)(T-s)\right)^2}{2\sigma^2(T-s)}  
\end{multline*}


Taking the first derivative with respect to \(x\):

\[\frac{\partial p_{gbm}(s, T, x, y)}{\partial x}=  p_{bm}(s, T, x, y)\left(\frac{\log\left(\frac{y}{x}\right)- \left(\alpha-\frac{\sigma^2}{2}\right) (T-s) }{\sigma^2 (T-s)x}\right)  \]

Taking the second derivative with respect to \(x\):

\begin{multline*}\frac{\partial^2 p_{bm}(s, T, x, y)}{\partial x^2}=  p_{bm}(s, T, x, y)*\\\left(  \left(\frac{\log\left(\frac{y}{x}\right)- \left(\alpha-\frac{\sigma^2}{2}\right) (T-s) }{\sigma^2 (T-s)x}\right)^2 -\frac{1}{\sigma^2 x^2 (T-s)} - \frac{\log\left(\frac{y}{x}\right)- \left(\alpha-\frac{\sigma^2}{2}\right) (T-s) }{\sigma^2 (T-s)x^2}   \right) \end{multline*}

Applying the coefficients,

\[\alpha x \frac{\partial p}{\partial x}=p \alpha \left(\frac{\log\left(\frac{y}{x}\right)- \left(\alpha-\frac{\sigma^2}{2}\right) (T-s) }{\sigma^2 (T-s)}\right)\]

\begin{multline*}\frac{1}{2} \sigma^2 x^2 \frac{\partial^2 p}{\partial x^2}\\=p\left( \frac{\left(\log\left(\frac{y}{x}\right)- \left(\alpha-\frac{\sigma^2}{2}\right) \right)^2 (T-s) }{2\sigma^2 (T-s)}- \frac{1}{ 2(T-s)} - \frac{\log\left(\frac{y}{x}\right)- \left(\alpha-\frac{\sigma^2}{2}\right) (T-s) }{ 2(T-s)}      \right)\end{multline*}


\[\frac{\partial p} {\partial s} + \frac{1}{2} \frac{\partial^2 p}{\partial x^2} =0\]

The Forward equation becomes

\[\frac{\partial p} {\partial T} -\frac{1}{2} \frac{\partial^2 p}{\partial y^2} =0\]

Taking the first derivative with respect to \(T\):

\[\frac{\partial p_{bm}(s, T, x, y)}{\partial T}=  \frac{1}{2}p_{bm}(s, T, x, y)\left(\frac{(y-x)^2}{(T-s)^2}-\frac{1}{T-s}\right)  \]

Taking the second derivative with respect to \(y\):

\[\frac{\partial^2 p_{bm}(s, T, x, y)}{\partial y^2}=  p_{bm}(s, T, x, y)\left(\frac{(y-x)^2}{(T-s)^2}-\frac{1}{T-s}\right)  \]

Combining, 

\[\frac{\partial p} {\partial T} -\frac{1}{2} \frac{\partial^2 p}{\partial y^2} =0\]






\end{document}